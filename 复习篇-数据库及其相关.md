# 数据库相关复习汇总

## Part1：MySQL必知必会

- SQL(Structured  Query  Language)，SQL是专门用来与数据库通信的语言。

```shell
#  SQL语句分类：
	DQL(数据查询语言)：查询语句，凡是select语句都是DQL
	DML(数据操作语言)：insert, delete, update，对表当中的数据进行增删改
	DDL(数据定义语言)：create, drop, alter，对表结构的增删改
	TCL(事务控制语言)：commit 提交事务，rollback 回滚事务
	DCL(数据控制语言)：grant 授权，revoke撤销权限等
```



```shell
# DISTINCT 关键字
	指示MySQL只返回不同的值。注意：DISTINCT 关键字只能使用在 SELECT 语句中，并且 DISTINCT 关键字应用于所有列而不仅是前置它的列。
	SELECT DISTINCT vend_id,prod_price,除非指定的两个列都相同，否则所有行都将被检索出来。
	参考博客：https://www.cnblogs.com/lbxBlog/p/9383174.html
```



```shell
# LIMIT 关键字
	为了在 SELECT 结果中返回第一行或前几行，可使用 LIMIT 子句。
	带一个值的 LIMIT 总是从第一行开始，给出的数为返回的行数，LIMIT 5，返回从第1行开始的5行
	带两个值的 LIMIT 可以指定从行号为第一个值的位置开始，LIMIT 5,5，返回从第5行开始的5行，
	行0：检索出来的第一行为行0，因此LIMIT 1,1返回第2行；
```



```shell
# ORDER BY 关键字
	ORDER BY 子句取一个或多个列的名字，据此对输出进行排序。
	排序方向：默认升序：ASC，降序排序：DESC
	多个列按不同顺序排序：
	SELECT prod_id,prod_price,prod_name
	FROM products
	ORDER BY prod_price DESC,prod_name; 按照prod_price降序，prod_name升序排序所选序列
# SQL 关键字顺序： SELECT -> FROM -> ORDER BY -> LIMIT
```



```shell
# WHERE 关键字
	WHERE 子句操作符：=(等于)  <>(不等于)  !=(不等于)  <(小于)  <=(小于等于)  >(大于)  >=(大于等于)  BETWEEN a AND b(在闭区间[a, b])
    IS NULL:检查具有NULL值的列，WHERE prod_price IS NULL;
    AND：用在 WHERE 子句中的关键字，用来指示检索满足所有给定条件的行；
    OR：用在 WHERE 子句中的关键处，用来表示检索匹配任一给定条件的行；
    IN： WHERE 子句中用来指定要匹配值的清单的关键字 WHERE vend_id (NOT) IN (1002, 1003);
# SQL 关键字顺序： SELECT -> FROM -> WHERE -> ORDER BY -> LIMIT
```



```shell
# 通配符 %  _
# LIKE 关键字：为在搜索子句中使用通配符，必须使用 LIKE 操作符。LIKE 指示 MySQL，后跟的搜索模式利用通配符匹配而不是直接相等匹配进行比较。
# %：在搜索串中，% 表示任何字符出现任意次数。
# _：在搜索串中，_ 总是匹配一个字符，不能多也不能少。
# MySQL中，'\' 具有转义作用，'\_' 表示普通的下划线，例如匹配名字中有下划线： LIKE '%\_%'；
```



```shell
# 正则表达式
	正则表达式的作用是匹配文本，将一个模式(正则表达式)与一个文本串进行比较。
	REGEXP 关键字：REGEXP 后所跟的东西为正则表达式；
	WHERE prod_name REGEXP '1000|2000'('\\[0-9] sticks?\\')
```

 

```shell
# 计算字段
	计算字段是运行在 SELECT 语句内创建的。
	# 拼接(concatenate)：将值联结到一起构成单个值；
		在 MySQL 的 SELECT 语句中，可使用 Concat() 函数来拼接两个列。
		Concat()拼接串，把多个串拼接起来形成一个较长的串： SELECT Concat(vend_name,' (',vend_country,')')
	# Trim() 函数
		RTrim()：去掉串右边的空格
		LTrim()：去掉串左边的空格
		Trim()：去掉串左右两边的空格
	# 使用别名
		 SELECT ... AS alias
```



```shell
# 使用数据处理函数
 # 文本处理函数
 	Upper()：转换为大写
 	Lower()：转换为小写
 	RTrim()：去掉串右边的空格
	LTrim()：去掉串左边的空格
	Trim()：去掉串左右两边的空格
	举例：SELECT vend_name, Upper(vend_name) AS vend_name_upcase
 # 日期处理函数
 	AddDate()：增加一个日期(天、周等)
 	AddTime()：增加一个时间(时、分等)
 	CurDate()：返回当前日期
 	CurTime()：返回当前时间
 	Date()：返回日期时间的日期部分
 	DateDiff()：计算两个日期之差
 	Date_Add()：高度灵活的日期运算函数
 	Date_Format()：返回一个格式化的日期或时间串
 	Day()：返回一个日期的天数部分
 	DayOfWeek()：对于一个日期，返回星期几
 	Hour()：返回一个日期的小时部分
 	Minute()：返回一个日期的分钟部分
 	Month()：返回一个日期的月份部分
 	Now()：返回当前日期和时间
 	Second()：返回一个时间的秒部分
 	Time()：返回一个日期时间的时间部分
 	Year()：返回一个日期的年份部分
 	SELECT cust_id, order_num
	FROM orders
	WHERE Date(order_date) = '2005-09-01';
```



```shell
# 汇总数据、聚集函数
 聚集函数(Aggregate Function)：运行在行组上，计算和返回单个值的函数。
 # AVG() 函数
 	AVG() 通过对表中行数计数并计算特定列值之和，求得该列的平均值。AVG() 可用来返回所有列的平均值，也可以用来返回特定列或行的平均值。
 	AVG() 函数忽略列值为NULL的行。
 	SELECT AVG(prod_price) AS avg_price
	FROM products
	WHERE vend_id = 1003;
 # COUNT() 函数
 	COUNT() 函数进行计数，可利用 COUNT() 确定表中行的数目或符合特定条件的行的数目。
 	COUNT() 函数有两种使用方式：
 		使用COUNT(*) 对表中行的数目进行计数，不管表列中包含的是空值(NULL)还是非空值。
 		使用COUNT(column) 对特定列中具有的值进行计数，忽略NULL值。
 # MAX() 函数
 	MAX() 函数返回指定列中的最大值。MAX() 要求指定列名。
 	MAX() 函数忽略列值为NULL的行。
 # MIN() 函数
 	MIN() 函数返回指定列中的最小值。MIN() 要求指定列名。
 	MIN() 函数忽略列值为NULL的行。
 # SUM() 函数
 	SUM() 用来返回指定列值的和。SUM() 也可以用来合计计算值。
 	SUM() 函数忽略行值为NUNLL的行。
 	SELECT SUM(item_price*quantity) AS total_price
	FROM orderitems
	WHERE order_num = 20005;
 # 聚集不同值
 	以上五个聚集函数都可以如下使用：
 		对所有的行执行计算，指定ALL参数或者不给参数(因为ALL是默认行为)；
 		只包含不同的值，指定 DISTINCT 参数；
 	SELECT AVG(DISTINCT prod_price) AS avg_price
	FROM products
	WHERE vend_id = 1003;
```



```shell
# 分组数据
	# 创建分组
		分组是在SELECT语句的GROUP BY子句中建立的。
		GROUP BY 子句指示MySQL分组数据，然后对每个分组而不是整个结果集进行聚集。
		SELECT COUNT(prod_id) AS num_prods
		FROM products
		GROUP BY vend_id;
	# 过滤分组
		HAVING 过滤分组，WHERE 过滤行；
		HAVING 和 WHERE的区别：
			WHERE在数据分组前进行过滤，HAVING在数据分组后进行过滤。WHERE 排除的行不包括在分组中。
		SELECT cust_id, COUNT(*) AS orders
		FROM orders
		GROUP BY cust_id
		HAVING COUNT(*) >= 2;
```



```shell
# SELECT 子句顺序
	SELECT			要返回的列或表达式	
	FROM			从中检索数据的表	
	WHERE			行级过滤			
	GROUP BY		分组说明		
	HAVING			组级过滤
	ORDER BY		输出排序序列
	LIMIT			要检索的行数
```



```shell
# 使用子查询
	举例：列出订购物品TNT2的所有客户
		第一步：查询订购物品TNT2物品的订单
			SELECT order_num
            FROM orderitems
			WHERE prod_id = 'TNT2';
		第二步：查询第一步订单对应的客户ID
			SELECT cust_id
			FROM orders
			WHERE order_num IN (20005,20007);
		第三步：返回第二步查询的顾客ID对应的信息
			SELECT cust_name, cust_contact
			FROM customers
			WHERE cust_id IN (10001,10004);
		使用子查询：
			SELECT cust_name, cust_contact
			FROM customers
			WHERE cust_id IN (
				SELECT cust_id
				FROM orders
				WHERE order_num IN (
					SELECT order_num
            		FROM orderitems
					WHERE prod_id = 'TNT2'
				)
			);
	举例：显示customers表中每个客户的订单总数
		第一步：客户订单总数
			SELECT COUNT(*)
			FROM orders
			WHERE orders.cust_id = 10001;
		第二步：查询所有客户订单
			SELECT cust_name,
	   			   cust_state,
	   				(SELECT COUNT(*)
					FROM orders
					WHERE orders.cust_id = customers.cust_id) AS orders
			FROM customers
			ORDER BY cust_name;
```



```shell
# 联结表
	外键(foreign key)：外键为某个表中的一列，它包含另一个表的主键值，定义了两个表之间的关系。
	在联结两个表时，实际上是将第一个表中的每一行与第二个表中的每一行配对。WHERE子句作为过滤条件，它只包含那些匹配给定条件(联结条件)的行。没有WHERE子句，第一个表中的每个行将与第二个表中的每个行配对，而不管它们逻辑上是否可以配在一起。
 # 笛卡尔积(cartesian product)：由没有联结条件的表关系返回的结果为笛卡尔积。检索出的行的数目将是第一个表    中的行数乘以第二个表中的行数。
 # 联结：
 	内部联结(可以联结多个表)：等值联结、非等值联结、自联结
 		举例：列出订购物品TNT2的所有客户
 		SELECT cust_name, cust_state
		FROM customers, orders, orderitems
		WHERE customers.cust_id = orders.cust_id
			AND orders.order_num = orderitems.order_num
			AND orderitems.prod_id = 'TNT2';
	外部联结：LEFT OUTER JOIN 选择左边表中的所有行
		SELECT customers.cust_id, orders.order_num
		FROM customers LEFT OUTER JOIN orders
		ON customers.cust_id = orders.cust_id;
```



```shell
# 组合查询
	MySQL允许执行多个查询(多个SELECT语句)，并将结果作为单个查询结果返回，这些组合查询通常称为并(union)或复合查询(compound query);
	有两种基本情况，其中需要使用组合查询：
		在单个查询中从不同的表返回类似结构的数据；
		对单个表执行多个查询，按单个查询返回数据；
#   UNION规则：
	UNION中的每个查询必须包含相同的列、表达式或聚集函数；
	列数据类型必须兼容：类型不必完全相同，但必须是DBMS可以隐含地转换的类型。
	UNION默认取消重复的行，若想匹配返回所有的行，可使用 UNION ALL 而不是 UNION；
	UNION只允许在最后一个SELECT语句中使用ORDER BY，排序所有SELECT语句返回的结果；
```



```shell
# 全文本搜索
	MyISM引擎支持全文本搜索；InnoDB引擎不支持全文本搜索。
	在创建表时(create table)指定FULLTEXT，MySQL自动维护该索引，在增加、更新或删除行时，索引随之自动更新。
	在索引之后，使用两个函数Match() 和 Against() 执行全文本搜索，其中 Match() 指定被搜索的列，Against() 指定要使用的搜索表达式。
	全文本搜索结果按等级值排序，等级由MySQL根据行中词的数目、唯一词的数目、整个索引中词的总数以及包含该词的行的数目计算出来。全文本搜索排除等级为0的行，搜索结果按等级以降序排序。
```



```shell
# 增删改
	插入数据：INSERT INTO 表名(字段名) VALUES (数据1),(数据2);
	删除数据：DELETE FROM 表名 WHERE 条件；
	修改数据：UPDATE 表名 SET a = b, c = d WHERE 条件；
```



```shell
# 使用存储过程
	存储过程简单来说：就是为以后的使用而保存的一条或多条MySQL语句的集合。
	创建存储过程：
		delimiter $$    # 将语句的结束符号从分号;临时改为两个$$(可以是自定义)
		CREATE PROCEDURE productpricing()
		BEGIN
			SELECT Avg(prod_price) AS priceaverage
			FROM products;
		END $$
		delimiter ;		# 将语句的结束符号恢复为分号
	调用存储过程：
		CALL productpricing();
	删除调用过程：
		DROP PROCEDURE productpricing;
	检查存储过程：
		SHOW CREATE PROCEDURE productpricing;
 # 变量：内存中一个特定的位置，用来临时处理数据，所有MySQL变量都必须以@开始；
 	MySQL支持IN(传递给存储过程)、OUT(从存储过程中传出)、INOUT(对存储过程传入传出)类型的参数。
```



```shell
# 管理事务处理
	InnoDB支持明确的事务处理管理，MyISAM不支持事务处理。
	事务处理(Transaction Processing)可以用来维护数据库的完整性，它保证成批的MySQL操作要么完全执行，要么完全不执行。
	事务处理是一种机制，用来管理必须成批执行的MySQL操作，以保证数据库不包含不完整的操作结果。利用事务处理，可以保证一组操作不会中途停止，它们或者作为整体执行，或者完全不执行。如果没有错误发生，整组语句提交(写到)数据库表。如果发生错误，则进行回退以恢复数据库到某个已知且安全的状态。
	事务处理的术语：
		事务(transaction)指一组SQL语句；
		回退(rollback)指撤销指定SQL语句的过程；
		提交(commit)指将未存储的SQL语句结果写入数据库表；
		保留点(savepoint)指事务处理中设置的临时占位符，可以回退部分事务。保留点在事务处理完成(执行一条ROLLBACK或COMMIT)后自动释放。
```



## Part2：MySQL技术内幕--InnoDB存储引擎

![image-20210213180033790](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210213180033790.png)

如上图所示，MySQL服务器逻辑架构从上往下可以分为三层：

（1）第一层：处理客户端连接、授权认证等。

（2）第二层：服务器层，负责查询语句的解析、优化、缓存以及内置函数的实现、存储过程等。

（3）第三层：存储引擎，负责MySQL中数据的存储和提取。

数据库的应用分为两类：一类是OLTP(在线事务处理)，如Blog、电子商务、网络游戏等；另一类是OLAP(在线分析处理)，如数据仓库、数据集市。

数据库(DataBase)和实例(instance)

**数据库**：物理操作系统文件或其他形式文件类型的集合，依照某种数据模型组织起来并存放于二级存储器中的数据集合，查了一下自己的电脑数据库文件是.ibd 结尾的文件；

**实例**：MySQL数据库由后台线程以及一个共享内存组成，共享内存可以被运行的后台线程所共享。数据库实例是软件，才是真正用于操作数据库文件的。

MySQL的组成：连接池组件、管理服务和工具组件、SQL接口组件、查询分析器组件、优化器组件、缓冲组件、**插件式存储引擎**、物理文件。

**MySQL数据库实例在系统上表现就是一个进程，MySQL被设计为一个单进程多线程架构的数据库。**

**MySQL插件式的表存储引擎，存储引擎是基于表的，而不是数据库。**

### MySQL体系结构和存储引擎

**InnoDB存储引擎**

- 待添加

**MyISAM存储引擎**

MyISAM存储引擎不支持事务、表锁设计，**支持全文索引**，主要面向一些OLAP在线分析处理(Online Analytical Processing)数据库应用。MyISAM存储引擎只缓存索引文件，而不缓冲数据文件。MyISAM存储引擎表由MYD和MYI组成，MYD用来存放数据文件，MYI用来存放索引文件。

**NDB存储引擎**

NDB存储引擎是一个集群存储引擎，数据全部放在内存中，因此主键查找的速度极快，并且通过添加NDB数据存储节点可以线性的提高数据库性能，是高可用、高性能的集群系统。

**Memory存储引擎**

Memory存储引擎将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据都将消失。适合用于存储临时数据的临时表，以及数据仓库中的维度表。默认使用哈希索引。

需要理解的是，连接MySQL操作时一个连接进程和MySQL数据库实例进行通信，从程序设计的角度来说，本质上是进程通信，TCP/IP、命名管道和共享内存、UNIX套接字。

### InnoDB存储引擎

#### InnoDB存储引擎体系架构：

- 内存池：负责维护所有进程/线程需要访问的多个内部数据结构、缓存磁盘上的数据、重做日志(redo log) 缓存；
- 后台线程：刷新内存池中的数据、将已修改的额数据文件刷新到磁盘文件中；
- 磁盘文件

**后台线程**

InnoDB存储引擎是多线程的模型，不同的线程负责处理不同的任务。

**1. Master  Thread**

InnoDB存储引擎的主要工作都是在一个单独的后台线程Master  Thread中完成的。

负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲、UNDO页的回收等。

**2. IO  Thread**

在InnoDB存储引擎中使用了大量的AIO异步IO(Async IO) 来处理写请求，IO  Thread的工作主要是负责这些IO请求的回调(call back)处理。

**3. Purge Thread**

事务被提交后，其所使用的undolog可能不在需要，因此使用Purge Thread来回收已经使用并分配的undo页，InnoDB支持多个Purge Thread。



**内存**

![InnoDB内存数据对象](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210206213555717.png)

**1. 缓冲池**

InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照**页**的方式进行管理，使用缓冲池技术协调CPU与磁盘速度的巨大差异来提高数据库的整体性能。读取页的操作将从磁盘读到的页“FIX”到缓冲池中，数据库中页的修改，先修改在缓冲池中的页再通过Checkpoint的机制刷新回磁盘。可以配置参数使数据库有多个缓冲池实例。

缓冲池中缓存的数据页类型有：索引页、数据页、undo页、插入缓冲(insert buffer)、自适应哈希索引(adaptive hash index)、InnoDB存储的锁信息(Lock Info)、数据字典信息（data dictionary）等。

InnoDB存储引擎中通过LRU（Latest Recent Used, 最近最少使用）算法对缓冲池进行管理，新读取的页插入**LRU List**的midPoint位置，防止某些SQL操作可能会式缓冲池中的页被刷出进而影响缓冲池效率。在LRU列表中的页被修改之后，称该页为**脏页(Dirty  Page)**，即缓冲池中的页和磁盘上的页的数据产生了不一致。

Flush List列表中的页即为脏页列表，所以脏页既存在于LRU List中也存在与Flush List中，LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新会磁盘。

**2. 重做日志缓冲**

InnoDB存储引擎每一秒钟将重做日志缓冲刷新到日志文件：

- Master  Thread 每一秒将重做日志缓冲刷新到重做日志文件；
- 每个事务提交时会将重做日志缓冲刷新到重做日志文件；
- 当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲刷新到重做日志文件。



#### Checkpoint技术

为了避免发生数据丢失的问题，当前事务数据库系统普遍都采用了 **Write  Ahead  Log**策略，即当事务提交时，先重做日志，再修改页。

Checkpoint所做的事情就是将缓冲池中的脏页刷新回到磁盘，InnoDB存储引擎中使用Fuzzy  Checkpoint进行页的刷新，刷新一部分脏页。



#### InnoDB关键特性

**插入缓冲**

**1. Insert Buffer**

对于非聚集索引（除了主键之外的索引）的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引是否在缓冲池中，若在则直接插入；若不在，则先放入到一个Insert Buffer对象中，然后再以一定的频率和情况进行Insert Buffer和辅助索引叶子节点的merge(合并)操作，这是通常能将多个插入合并到一个操作中(因为在一个索引页中)，这就大大提高了对于非聚集索引插入的性能。

Insert Buffer的使用需要同时满足两个条件：索引是辅助索引(Secondary  Index)；索引不是唯一(Unique)的；

**2. Change Buffer**

InnoDB存储引擎可以对DML操作——INSERT、DELETE、UPDATE都进行缓冲，分别是 Insert Buffer、Delete Buffer、Purge Buffer；

Change Buffer 适用的对象依然是非唯一的辅助索引。

**3. Insert Buffer的内部实现**

全局有一棵**Insert Buffer B+树**，负责对所有的表的辅助索引进行Insert Buffer。

**两次写(doublewrite)**

在**应用重做日志**前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页在进行重做，这就是doublwrite；

具体过程如下：doublewrite由两部分组成：一部分是**内存**中的doublewrite buffer(2MB)，另一部分是物理磁盘上共享表空间中连续的128个页(2MB)。在对缓冲池中的脏页进行刷新时，并不直接写磁盘而是会通过memcpy函数将脏页先复制到内存中的doublewrite buffer，之后通过doublewrite buffer再分两次，每次1MB顺序地写入共享表空间的物理磁盘上，然后调用fsync函数同步磁盘。完成doublewrite也的写入后再将doublewrite buffer中的页写入各个表空间文件中。

**自适应哈希索引**

InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引，即自适应哈希索引(Adaptive Hash Index, AHI)。

AHI有一个要求，即对这个页的连续访问模式必须是一样的。并且哈希索引只能用来搜索等值的查询。

**异步IO**

为了提高磁盘操作性能，当前的数据库系统都采用异步IO(Asynchronous IO，AIO)的方式来处理磁盘操作。与AIO对应的是Sync IO，即每进行一次操作，需要等待此次操作结束才能继续接下来的操作。

AIO：用户可以在发出一个IO请求后立即再发出另一个IO请求，当全部IO请求发送完毕后等待所有IO操作的完成。

AIO的另一个优势是可以进行IO Merge操作，即将多个IO合并为一个IO操作。

**刷新邻接页**

当刷新一个脏页时，InnoDB存储引擎会检测该页所在区的所有页，如果是脏页则一起刷新。



### 文件

#### InnoDB存储引擎文件

**表空间文件**

共享表空间 + 独立表空间

InnoDB采用将存储的数据按表空间(tablespace)进行存放的设计。用户可以通过多个文件组成一个表空间，同时制定文件的属性，如：

```shell
[mysqld]
innodb_data_file_path = /db/ibdata1:2000M;/dr2/db/ibdata2:2000M:autoextend
```

若不同的文件位于不同的磁盘上，磁盘的负责可能被平均，因此可以提高数据库的整体性能。

```shell
设置 innodb_data_file_path 参数后，所有基于InnoDB存储引擎的表的数据都会记录到该共享表空间中(share tablespace)。
设置 innodb_file_per_table 参数后，用户可以将每个基于InnoDB存储引擎的表产生一个独立表空间，命名：表明.ibd。需要注意的是单独的表空间存储表的数据、索引和插入缓冲BITMAP等信息，其余信息还是存放在默认的表空间中(即共享表空间中)。
```

**重做日志文件(redo log flie)**

重做日志文件记录了对于InnoDB存储引擎的事务日志。当实例或介质失败时，InnoDB存储引擎会使用重做日志恢复到掉电前的时刻，以此来保证数据的完整性。



### 表

本章将从InnoDB存储引擎表的逻辑存储及实现开始介绍，然后将重点分析表的物理存储特征，即数据在表中是如何组织和存放的。简单来说，表就是关于特定实体的数据集合，这也是关系型数据库模型的核心。

#### 索引组织表

在InnoDB存储引擎中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表(index organized table)。在InnoDB存储引擎表中，每张表都有主键（Primary Key），如果在创建表时没有显示地定义主键，则InnoDB存储引擎会按如下方式选择或创建主键：

- 首先判断表中是否有非空的唯一索引（Unique NOT NULL），如果有，该列即为主键；当表中有多个非空唯一索引时，InnoDB存储引擎将选择建表时第一个定义的非空唯一索引作为主键。
- 如果不符合上述条件，InnoDB存储引擎自动创建一个6字节大小的指针。



#### InnoDB逻辑存储结构

从InnoDB存储引擎的逻辑结构看，所有数据都被逻辑地存放在一个空间中，称为表空间(tablespace)。表空间又由段、区、页组成，页在一些文档中有时也称为块。

**表空间**

表空间可以看做是InnoDB存储引擎逻辑结构的最高层，所有的数据都放在表空间中。InnoDB默认有一个共享表空间。

若启用`innodb_file_per_table`参数(默认开启)，在每张表的表空间内存放的只是数据、索引和插入缓冲BitMap页。

共享表空间中存放：回滚信息、插入缓冲索引页、系统事务信息、二次写缓冲等；

**段**：表空间是由各个段组成的，常见的段有数据段、索引段、回滚段等。InnoDB存储引擎表是索引组织的，数据段即为B+树的叶子节点，索引段即为B+树的非叶子节点。

**区**：区是由连续页组成的空间，在任何情况下每个区的大小都为1MB。在默认情况下，InnoDB存储引擎页的大小为16KB，即一个区中有连续64个页。表空间在每个段开始之前，先用32个页大小的碎片页来存放数据，目的：对于一些小表可以在开始时申请较少的空间节省磁盘容量的开销。

**页、行**：页是InnoDB磁盘管理的最小单位，默认页大小为16KB。InnoDB存储引擎是面向列的，数据是按行进行存放的。每个页最多允许存放 `16KB / 2 - 200 = 7992`行记录。



#### InnoDB行记录格式

![image-20210208222821080](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210208222821080.png)

- 变长字段长度最大为2字节，因为VARCHAR最大长度为65535。
- 注意：数据列中的NULL值，除了占有NULL标志位，实际存储不占有任何空间。不管是CHAR 或VARCHAR类型，在compact格式下NULL都不占用任何存储空间。
- Redundant行记录格式下，VARCHAR类型NULL都不占用任何存储空间，CHAR类型NULL需要占用空间。

**行溢出数据**

一般情况下，InnoDB存储引擎的数据都是存放在页类型为B-tree node中，但是当发生行溢出时，行结构存储偏移量指向行溢出页，数据存放在页类型为 Uncompress BLOB页中。

VARCHAR(N)类型, N是指字节值，最大支持65535单位是字节，并且65535是所有VARCHAR列的长度总和。

CHAR(N) 类型，N指字符长度。



#### 约束

一般来说，数据完整性有以下三种形式：

- 实体完整性保证表中有一个主键；
- 域完整性保证数据每列的值满足特定的条件；
- 参照完整性保证两张表之间的关系；

对于InnoDB存储引擎而言，提供了一下几种约束：Primary  Key,   Unique  Key,  NOT  NULL,  Foreign  Key,  Default。

**约束与索引**：约束更是一个逻辑的概念，用来保证数据的完整性，而索引是一个数据结构，既有逻辑上的概念在数据库中还代表着物理存储的方式。

**外键约束**

外键约束中，被引用的表称为父表，引用的表称为子表，外键定义时的ON  DELETE 和 ON UPDATE表示在对父表进行DELETE和UPDATE操作时对子表的操作：

- CASCADE：子表与父表进行相同的DELETE/UPDATE操作
- SET NULL：子表的列允许null值时，设置为null；
- NO ACTION/RESTRICT(默认)：抛出错误不允许父表发生DELETE/UPDATE操作

InnoDB存储引擎在外键建立时会自动地对该列加一个索引。MySQL数据库的外键约束都是即时检查(immediate check)。

**索引**

**索引分类**，分为

主键索引（必须指定为“PRIMARY KEY”，没有PRIMARY Index）、

唯一索引（unique index，一般写成unique key）、

普通索引(index，只有这一种才是纯粹的index)

建表语句中单独的KEY关键字，表示普通索引，例：`KEY 'parent_id' (parent_id)`



#### 分区表

支持分区功能的存储引擎：InnoDB、MyISAM、NDB；

分区的过程是将一个表或索引分解为多个更小、更可管理的部分。

MySQL数据库支持的分区类型为水平分区(指将同一表中不同行记录分配到不同的物理文件中)，此外，MySQL数据库的分区是局部分区索引，一个分区中既存放了数据又存放了索引。不论创建何种类型的分区，如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分。如果建表时没有指定主键、唯一索引，可以指定任何一个列为分区列。

**RANGE分区**：行数据基于属于一个给定连续区间的列值被放入分区，主要用于日期列的分区。

```sql
PARTITION BY RANGE(id)(
    PARTITION p0 VALUES LESS THAN (10),
    PARTITION p1 VALUES LESS THAN (20);
)
```

**LIST分区**：面向的是离散的值；

```sql
PARTITION BY RANGE(b)(
    PARTITION p0 VALUES IN (1,3,5,7,9),
    PARTITION p1 VALUES IN (0,2,4,6,8);
)
```

在用INSERT插入多个行数据的过程中遇到分区未定义的值时，MyISAM和InnoDB存储引擎不同，MyISAM会将之前的行数据都插入，但之后的数据不会插入。而InnoDB存储引擎将其视为一个事务，因此没有任何数据插入。

**HASH分区**：根据用户自定义的表达式的返回值来进行分区，返回值不能为负数。用户基于将要进行哈希分区的列值指定一个列值或表达式，以及指定被分区的表将要被分割成的分区数量。

```sql
PARTITION BY HASH (YEAR(B))
PARTITION 4;
```

**KEY分区**：根据MySQL数据库提供的哈希函数来进行分区。

对于OLAP(在线分析处理)的应用，分区可以提高查询的性能；对于OLTP需要确认数据的访问模式再考虑分区处理。



### 索引与算法

#### InnoDB存储引擎索引概述

InnoDB存储引擎支持一下几种常见的索引：B+树索引、全文索引、哈希索引。

InnoDB存储引擎支持的哈希索引是自适应的，InnoDB存储引擎会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引。

**B+ 树索引**是关系型数据库系统中查找最为常用和最为有效的索引。B+ 树索引并不能找到一个给定键值的具体行。B+ 树索引能找到的只是被查找数据行所在的**页**。然后数据库通过把页读入到内存，再**在内存中进行查找**，最后得到要查找的数据。

对于某一条具体记录的查询是通过对Page Directory进行二分查找得到的。   

  

#### B+ 树索引

B+ 树索引的本质就是 B+ 树在数据库中的实现。B+ 索引在数据库中有一个特点就是高扇出性，因此在数据库中B+树的高度一般都在2 ~ 4层。数据库中的B+ 树索引可以分为聚集索引(clustered index)和辅助索引(secondary index)，但不管是聚集索引还是辅助索引，其内部都是B+树的，即高度平衡的，叶子节点存放着所有的数据。聚集索引与辅助索引不同的是，叶子节点存放的是否是一整行的信息。

**聚集索引**

InnoDB存储引擎表就是一张索引组织表，即表中的数据按照主键顺序存放。而聚集索引就是按照**每张表的主键构造一棵B+树**，同时**叶子节点中存放的即为整张表的行记录数据**，也将聚集索引的**叶子节点称为数据页**。聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。同B+树数据结构一样，每个数据页都通过一个双向链表来进行链接。

由于实际的数据页只能按照一棵B+树进行排序，因此**每张表只能拥有一个聚集索引**。在多数情况下，查询优化器倾向于采用聚集索引，因为聚集索引能够在B+树索引在叶子节点上直接找到数据。

**数据页上存放的是完整的每行的记录，而在非数据页的索引页中，存放的仅仅是键值(即表的主键)及指向数据页的偏移量。**

聚集索引的存储并不是物理上连续的，而是逻辑上连续的。这其中有两点：一是前面说过的页通过双向链表链接，页按照主键的顺序排序；另一点是每个页中的记录也是通过双向链表进行维护的(行记录中有Record Header)。

聚集索引的另一个好处是：对于主键的排序查找和范围查找速度很快。

**辅助索引**

对于辅助索引(Secondary  Index, 也称非聚集索引)，叶子节点并不包含行记录的全部数据。叶子节点除了包含键值(辅助索引列的值)以外，每个叶子节点中的索引行还包含了一个书签（bookmark）。该书签用来告诉InnoDB存储引擎哪里可以找到与索引相对应的行数据。由于InnoDB存储引擎是索引组织表，因此**InnoDB存储引擎的辅助索引的书签就是相应行数据的聚集索引键(即主键)**。

辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引(即聚集索引)来找到一个完整的行记录。

MySQL对于主键的创建和删除过程：

- 首先创建一张新的临时表，表结构为通过命令ALTER TABLE新定义的结构；
- 然后把原表中数据导入到临时表
- 接着删除原表
- 最后把临时表重命名为原来的表名。

辅助索引的创建和删除：Fast  Index  Creation(FIC，快速索引创建)，对创建索引的表加S锁；删除：更新内部视图，将辅助索引的空间标记为不可用，删除MySQL数据库内部视图上对该表的索引定义即可。



#### Cardinality值

添加B+ 树索引的时机：在访问表中很少一部分时使用B+ 树索引才有意义。如果某个字段的取值范围很广，几乎没有重复，即属于高选择性，则此时使用B+ 树索引是最合适的。

Cardinality值表示索引中不重复记录数量的**预估值**。

**InnoDB存储引擎的Cardinality统计**

Cardinality的统计都是通过采样(Sample)的方法来完成的。在InnoDB存储引擎中，Cardinality统计信息的更新发生在两个操作中：Insert和Update。InnoDB存储引擎内部对更新Cardinality信息的策略为：表中1/16的数据已发生过变化；stat_modified_counter > 20亿。

InnoDB存储引擎统计Cardinality值通过对随机取得8个叶子节点预估得到的。



#### B+ 树索引的使用

**联合索引**：指对表上的多个列进行索引。

**覆盖索引**：从辅助索引中就可以查询得到的记录，而不需要查询聚集索引中的记录。



#### 哈希算法

InnoDB存储引擎使用哈希算法来对字典进行查找，其冲突机制采用链表方式，哈希函数采用除法散列方式。



#### 全文检索(Full - Text Search)

全文检索是将存储于数据库中的整本书或整篇文章中的任意内容信息查找出来的技术。它可以根据需要获得全文中有关章、节、段、句、词等信息，也可以进行各种统计和分析。

全文检索通常使用倒排索引来实现，在辅助表中存储了单词与单词自身在一个或多个文档中所在位置之间的映射，利用关联数组实现，其拥有两种表现形式：

- inverted file index，其表现形式为{单词，单词所在文档的ID}
- full inverted index，其表现形式为{单词，(单词所在文档的ID，在具体文档中的位置)}

**InnoDB全文检索**

InnoDB存储引擎全文检索采用 full inverted index的方式。在InnoDB存储引擎中，将(DocumentId, Position)视为一个“ilist”。因此在全文检索的表中，有两个列，一个是word字段，另一个是ilist字段，并且**在word字段上设有索引**。

倒排索引需要将word存放到一张表中，这个表称为 Auxiliary  Table(辅助表)。在InnoDB存储引擎中，为了提高全文检索的并行功能，共有6张辅助表。辅助表是持久的表，存放于**磁盘**上。

对于InnoDB存储引擎而言，其总是在事务提交时将分词写入到FTS Index Cache(全文检索索引缓存)，然后再通过批量更新写入到磁盘。当数据库关闭时，在FTS Index Cache中的数据库会同步到磁盘上的Auxiliary Table中。

文档中分词的删除，在事务提交时不删除磁盘Auxiliary Table中的记录，而只是删除FTS Cache  Index中的记录。



### 锁

锁是数据库系统区别于文件系统的一个关键特性，锁机制用于管理对共享资源的并发访问。数据库系统使用锁是为了支持对**共享资源**进行并发访问，提供数据的完整性和一致性。

InnoDB存储引擎锁提供一致性的非锁定读、行级锁支持。行级锁没有相关额外的开销，并可以同时得到并发性和一致性。

通过锁机制可以实现事务的隔离性要求，使得事务可以并发地工作；

#### InnoDB存储引擎中的锁

**锁的类型**

InnoDB存储引擎实现了如下两种标准的**行级锁(同一记录)**：

- 共享锁(S Lock)，允许事务读一行数据；
- 排他锁(X Lock)，允许事务删除或更新一行数据；
- 意向共享锁(IS Lock)，事务想要获得一张表中某几行的共享锁；
- 意向排他锁(IX Lock)，事务想要获得一张表中某几行的排他锁。

InnoDB存储引擎支持多粒度(granular)锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在。为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持意向锁，意向锁即为表级别的锁，设计目的主要是为了在一个事务中揭示下一行将被请求的锁类型。InnoDB存储引擎中锁的兼容性：

|      | IS     | IX     | S      | X      |
| ---- | ------ | ------ | ------ | ------ |
| IS   | 兼容   | 兼容   | 兼容   | 不兼容 |
| IX   | 兼容   | 兼容   | 不兼容 | 不兼容 |
| S    | 兼容   | 不兼容 | 兼容   | 不兼容 |
| X    | 不兼容 | 不兼容 | 不兼容 | 不兼容 |



**一致性非锁定读**

一致性的非锁定读(consistent  nonlocking read) 是指InnoDB存储引擎通过行多版本控制(multi versioning)的方式来读取当前执行时间数据库中行的数据。

非锁定读不需要等待访问行上X锁 (排他锁) 的释放，读取行的一个快照数据。非锁定读是InnoDB存储引擎的默认读取方式，即**读取不会占用和等待表上的锁**。

快照数据是指该行的之前版本的数据，该实现时通过undo(回滚段)来完成，而undo用来在事务中回滚数据，因此快照数据本身是没有额外的开销。

一个行记录可能有不止一个快照数据，一般称这种技术为行多版本技术，由此带来的并发控制，称之为多版本并发控制(Multi  Version  Concurrency Control, **MVCC**)。

在事务隔离级别 READ COMMITED 和 REPEATABLE READ(默认事务隔离级别)下，InnoDB存储引擎使用非锁定一致性读。然而对于快照数据定义却不同，在**READ   COMMITED** 事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据。而在 **REPEATABLE READ** 事务隔离级别下，对于快照数据，非一致性读总是读取**事务开始**时的行数据版本。



**一致性锁定读**

在某些情况下，用户需要显示的对数据库读取操作进行加锁以保证数据逻辑的一致性。

InnoDB存储引擎对于SELECT语句支持两种一致性的锁定读(locking  read)操作：

- SELECT ...  FOR  UPDATE，读取行加X锁；
- SELECT ...  LOCK IN SHARE MODE，读取行加S锁；

InnoDB存储引擎的内存结构中，对每个含有自增长值的表都有一个自增长计数器(auto - increment  counter)，使用互斥量去对内存中的计数器进行累加的操作；

InnoDB存储引擎中，对于外键的插入或更新需要查询父表中的记录，主动对父表加S锁：SELECT ...  LOCK IN SHARE MODE。



#### 锁的算法

InnoDB存储引擎有3种行锁的算法，其分别是：

- Record  Lock：单个行记录上的锁；
- Gap  Lock：间隙锁，锁定一个范围，但不包含记录本身；
- Next - Key  Lock：Gap Lock + Record Lock，锁定一个范围并锁定记录本身

当查询的索引含有**唯一**属性时，InnoDB存储引擎会对Next - Key  Lock 进行优化，将其降级为Record Lock，即仅锁住索引本身，而不是范围。

InnoDB存储引擎还会对辅助索引下一个键值加上 gap lock，Gap Lock的作用是为了阻止多个事务将记录插入到统一范围内，而这会导致Phantom Problem(幻象问题)的产生。

**解决幻象问题**

幻象问题(Phantom  Problem)是指在同一事务下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。

InnoDB默认事务隔离级别(REPEATABLE  READ)，在该隔离级别下，采用 Next - Key  Locking的方式来加锁；

不论采用 select ... for update 或者 select ... in share mode; 一致性读添加X或S锁都会存在gap lock；



#### 锁问题

**脏读**

**脏页**指的是在缓冲池中已经被修改的页，但是还没有刷新到磁盘中，即数据库实例内存中的页和磁盘中的页的数据是不一致的，当然在刷新到磁盘之前，日志都已经被写入到了重做日志文件中。

**脏数据**是指事物对缓冲池中行记录的修改，并且还没有被提交(commit)。

脏读指的就是在不同的事务下，当前事务可以读到另外事务**未提交**的数据，简单来说就是可以读到脏数据。

**不可重复读(幻象问题)**

不可重复读是指在一个事务内多次读取**同一数据集合**。在这个事务还没有结束时，另外一个事务也访问该同一数据集合，并做了一些DML操作。因此在第一个事务中的两次读数据之间，由于第二个事务的修改那么第一个事务两次读到的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的情况，这种情况称为不可重复读。

不可重复读和脏读的区别是：脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据，但是其违反了数据库事务一致性的要求。

很多数据库厂商(Oracle、Microsoft SQL Server)将其数据库事务的默认隔离级别设置为READ  COMMMITED，在这种隔离级别下允许不可重复读现象。

在InnoDB存储引擎中，通过使用Next - Key Lock 算法来避免不可重复读的问题，在MySQL官方文档中将不可重复读的问题定义为 Phantom  Problem即幻象问题。在Next - Key Lock 算法下，对于索引的扫描，布局是锁住扫描到的索引而且还锁住这些索引覆盖的范围(gap)。

**丢失更新**

一个事务的更新操作会被另一个事务的更新操作所覆盖，从而导致数据的不一致。



#### 阻塞

因为不同锁之间的兼容性关系，在有些时刻一个事务中的锁需要等待另一个事务中的锁释放它锁占用的资源，这就是阻塞；

阻塞并不是一件坏事，其是为了确保事务可以并发且正常地运行。



#### 死锁

死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。

当前数据库解决死锁问题：1. 超时等待机制；2. wait - for graph(等待图)；

wait - for graph要求数据库保存一下两种信息：锁的信息链表、事务等待链表。

wait - for graph 是一种较为主动的死锁检测机制，在每个事务请求锁并发等待时都会判断是否存在回路，若存在则有死锁，通常来说InnoDB存储引擎选择回滚undo量最小的事务。采用非递归的深度优先算法实现 wait - for graph 死锁检测。



### 事务

#### 认识事务

事务(Transaction)是数据库区别于文件系统的重要特性之一。**事务**会把数据库从一种状态转换为另一种**一致状态**。在数据库提交工作时，可以确保要么所有修改都已经保存了，要么所有修改都不保存。事务是访问并更新数据库中各种数据项的一个程序执行单元。

```shell
#  事务的ACID特性
#  参考博客：https://www.cnblogs.com/kismetv/p/10331633.html
	A(Atomicity)原子性：原子性指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功，才算整个事务成功。事务中任何一个SQL语句执行失败，已经执行成功的SQL语句也必须撤销，数据库状态应该退回到执行事务前的状态。
	C(Consistency)一致性：一致性指事务将数据库从一种状态转变为下一种一致的状态。在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。一致性是指事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。数据库的完整性约束包括但不限于：实体完整性（如行的主键存在且唯一）、列完整性（如字段的类型、大小、长度要符合要求）、外键约束、用户自定义完整性（如转账前后，两个账户余额的和应该不变）。可以说，一致性是事务追求的最终目标：前面提到的原子性、持久性和隔离性，都是为了保证数据库状态的一致性。此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。
		实现一致性的措施包括：
		保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证
		数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等
		应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致
	I(isolation)隔离性：事务的隔离性要求每个读写事务的对象对其他事务的操作对象能相互分离，即该事务提交前对其他事务都不可见，通常这使用锁来实现。
	(一个事务)写操作对(另一个事务)写操作的影响：锁机制保证隔离性
	(一个事务)写操作对(另一个事务)读操作的影响：MVCC保证隔离性
	D(durability)持久性：事务一旦提交，其结果就是永久性的。即使发生宕机等故障，数据库也能将数据恢复。
```

**事务分类**

**扁平事务(Flat  Transaction)**：在扁平事务中，所有操作都处于同一层次，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束，其间的操作是原子的，要么都执行要么都回滚。扁平事务的主要限制是不能提交或回滚事务的某一部分，或分几个步骤提交。

**带有保存点的扁平事务(Flat  Transactions  with  Savepoint)**：除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到**同一事务中较早的一个状态**。保存点用来通知系统应该记住事务当前的状态，以便当之后发生错误时，事务能回到保存点当时的状态。保存点用SAVE WORK函数来建立，通知系统记录当前的处理状态。当出现问题时，保存点能用作内部的重启动点，根据应用逻辑决定是回到最近一个保存点还是其他更早的保存点。

限制：带有保存点的扁平事务当发生系统崩溃时，所有的保存点都将消失，因为其保存点是易失的(volatile)而非持久的(persistent)。这意味着进行恢复时，事务需要从开始出重新执行，而不能从最近的一个保存点继续执行。

**链事务(Chained  Transaction)**：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传递给下一个要开始的事务。注意：提交事务操作和开始下一个事务操作将合并为一个原子操作。

**嵌套事务(Nested  Transaction)**：是一个层次结构框架，由一个顶层事务(top - level  transaction) 控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务其控制着每一个局部的变换。实际的工作交给叶子节点来完成，高层的事务仅负责逻辑控制，决定何时调用相关的子事务，即使一个系统不支持嵌套事务也可以通过保存点技术来模拟嵌套事务。

**分布式事务(Distributed  Transations)**：通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。

对于InnoDB存储引擎来说，支持扁平事务、带有保存点的事务、链事务、分布式事务。



#### 事务的实现

**redo log**

重做日志由两部分组成：一是内存中的重做日志缓冲(redo log buffer)，其是易失的；二是重做日志文件(redo  log  file) ，其是持久的。InnoDB是事务的存储引擎，其通过 Force  Log  at  Commit 机制实现事务的持久性，即当事务提交(Commit)时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的Commit操作完成才算完成。为了确保每次日志都写入重做日志文件，在每次将重做日志缓冲写入重做日志文件后，InnoDB存储引擎都需要调用一次fsync操作。

在InnoDB存储引擎中，重做日志都是以512字节进行存储的称为重做日志块。重做日志块的大小和磁盘扇区大小一样都是512字节，因此重做日志的写入可以保证原子性不需要doublewrite技术。(回顾：应用重做日志时需要doublewrite技术)

InnoDB存储引擎运行过程中，log buffer根据一定的规则将内存中的log block 刷新到磁盘，这个规则具体是：

事务提交时、当log  buffer 中有一半的内存空间已经被使用时、log  Checkpoint 时；

LSN(Log  Sequence  Number)代表日志序列号，其表示的含义有：重做日志写入的总量、Checkpoint 的位置、页的版本；LSN 不仅记录在重做日志中，还存在于每个页中。在页中LSN表示该页最后刷新时LSN的大小。

重做日志中记录的是页的物理修改操作，若插入涉及B+ 树的split，可能会有更多的页需要记录日志。



**undo**

在对数据库进行修改时，InnoDB存储引擎不仅会产生redo，还会产生一定量的undo。redo存放在重做日志文件中，undo存放在数据库的undo段中，undo段位于共享表空间内。undo是逻辑日志，只是将数据库逻辑地恢复到原来的样子。

当InnoDB存储引擎回滚时，实际上做的是与先前相反的工作，对于每个INSERT，完成一个DELETE；对于每个DELETE，执行一个INSERT；对于每个UPDATE，执行一个相反的UPDATE；

除了回滚操作，undo的另一个作用是MVCC，即在InnoDB存储引擎中MVCC的实现是通过undo来完成。当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过undo读取之前的版本信息，以此实现非锁定读。

undo log会产生redo log，也就是undo log的产生会伴随着redo log的产生，因为 undo log 也需要持久性的保护。

事务在undo log segment 分配页并写入undo log的这个过程同样需要写入重做日志，当事务提交时，InnoDB存储引擎会做以下两件事情：

- 将undo log 放入列表中，以供之后的 purge 操作；
- 判断 undo log 所有的页是否可以重用，若可以分配给下个事务使用。

事务提交后并不能马上删除 undo log及 undo log 所在的页。这是因为可能还有其他事务需要通过 undo log 来得到行记录之前的版本。故事务提交时将 undo log放入一个链表中，是否可以删除undo log 以及 undo log 所在的页由 purege线程来判断。

undo  log 格式：

- insert undo log：insert操作中产生的undo log，根据隔离性的要求，insert 操作的记录只对事务本身可见，对其他事务不可见，故该 undo log 可以在事务提交后直接删除；
- update  undo  log：对delete和update操作产生的undo log，该undo  log可能需要提供MVCC机制，因此不能在事务提交时就进行删除，提交时放入一个链表中，是否可以删除由 purege线程来判断；



**purge**：purge用于最终完成delete和update操作，这样设计是因为InnoDB存储引擎支持MVCC，所以记录不能在事务提交时立即进行处理。

对于InnoDB存储引擎来说，事务提交时会进行两个阶段的操作：

1）修改内存中事务对应的信息，并且将日志写入重做日志缓冲；

2）调用fsync将确保日志都从重做日志缓冲写入磁盘；



#### 事务的隔离级别

READ UNCOMMITTED：存在脏读现象，读取到了未提交的数据；

READ COMMITTED：出现不可重复读的情况，即幻读现象；(Oracle数据库默认的事务隔离级别)

REPEATABLE READ：读取到的数据是数据快照；(MySQL默认的事务隔离级别)

SERIALIZABLE：解决了所有问题，需4要事务排队；



#### 分布式事务

InnoDB存储引擎提供了对XA事务(X/Open DTP组织定义的两阶段提交协议)的支持，并通过XA事务来支持分布式事务的实现。分布式事务指的是允许多个独立的事务资源参与到一个全局的事务中。全局事务要求在其中的所有参与的事务要么都提交要么都回滚。

分布式事务使用两段式提交(two-phase  commit)的方式。在第一阶段，所有参与全局事务的节点都开始准备（Prepare），告诉事务管理器准备提交；在第二阶段，事务管理器告诉资源管理器执行回滚还是提交。如果任何一个节点显示不能提交，则所有节点都被告知回滚。



### MVCC

MVCC最大的优点是读不加锁，因此读写不冲突，并发性能好。InnoDB实现MVCC，多个版本的数据可以共存，主要基于以下技术及数据结构：

1）隐藏列：InnoDB中每行数据都有隐藏列，隐藏列中包含了本行数据的事务id、指向undo log的指针等。

2）基于undo log的版本链：前面说到每行数据的隐藏列中包含了指向undo log的指针，而每条undo log也会指向更早版本的undo log，从而形成一条版本链。

3）ReadView：通过隐藏列和版本链，MySQL可以将数据恢复到指定版本；但是具体要恢复到哪个版本，则需要根据ReadView来确定。所谓ReadView，是指事务（记做事务A）在某一时刻给整个事务系统（trx_sys）打快照，之后再进行读操作时，会将读取到的数据中的事务id与trx_sys快照比较，从而判断数据对该ReadView是否可见，即对事务A是否可见。

trx_sys中的主要内容，以及判断可见性的方法如下：

- low_limit_id：表示生成ReadView时系统中应该分配给下一个事务的id。如果数据的事务id大于等于low_limit_id，则对该ReadView不可见。
- up_limit_id：表示生成ReadView时当前系统中活跃的读写事务中最小的事务id。如果数据的事务id小于up_limit_id，则对该ReadView可见。
- rw_trx_ids：表示生成ReadView时当前系统中活跃的读写事务的事务id列表。如果数据的事务id在low_limit_id和up_limit_id之间，则需要判断事务id是否在rw_trx_ids中：如果在，说明生成ReadView时事务仍在活跃中，因此数据对ReadView不可见；如果不在，说明生成ReadView时事务已经提交了，因此数据对ReadView可见。



### 备份与恢复、性能调优未看







## Part3：Redis 必知必会

> NoSQL = Not Only SQL(不仅仅是SQL)，泛指非关系型数据库；

Redis (Remote  Dictionary  Server)，即远程字典服务；是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并且提供多种语言的API。Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。

Redis是一个开源的（BSD许可）的，内存中的数据结构存储系统，可以用作**数据库**、**缓存**和**消息中间件MQ**，支持多种类型的数据结构，如字符串（String），散列（hashes），列表（list），集合（sets），有序集合（sorted sets）与范围查询 bitmaps，hyperloglogs和地理空间（geospatial）索引半径查询。Redis内置了复制（replication），LUA脚本（Lua scripting），LRU驱动事件，事务和不同级别的磁盘持久化，并通过Redis哨兵和自动分区提供高可用性。



### Redis 配置文件详解

```bash
bind 127.0.0.1		#绑定的IP
protected-mode yes		#保护模式，默认开启
port 6380			#端口

daemonize yes		#以守护进程的方式运行

pidfile /var/run/redis_6379.pid		#以后台方式运行，需要指定一个pid文件

#日志
# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably)	生产环境
# warning (only very important / critical messages are logged)
loglevel notice

logfile ""		#日志的文件位置名

databases 16		#数据库的数量，默认是16个

always-show-logo yes		#是否总是显示快照

#900s内有1个key发生了修改，则进行持久化操作；
save 900 1
#30s内有10个key发生了修改，则进行持久化操作；
save 300 10
#60s内有10000个key发生了修改，则进行持久化操作；
save 60 10000

stop-writes-on-bgsave-error yes		#持久化出错，是否继续工作

rdbcompression yes		#是否压缩rdb文件，需要消耗一些CPU资源

rdbchecksum yes			#保存rdb文件的时候，进行错误的检查校验

dir ./					#rdb 文件保存的目录

appendonly no		#默认是不开启aof模式的，默认使用rdb方式持久化，在大部分情况下rdb模式完全够用

appendfilename "appendonly.aof"		#持久化的文件的名字

# appendfsync always		#每次修改都会sync，消耗性能
appendfsync everysec		#每秒执行一次sync，可能会丢失这1s的数据
# appendfsync no			#不执行sync，操作系统自己同步数据，速度最快
```



### Redis 持久化

**RDB（Redis DataBase）**

在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是Snapshot快照，恢复时是将快照文件直接读到内存中。

Redis会单独创建(fork)一个子进程来进行持久化，会先将数据写入一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的，确保了极高的性能。

默认是RDB，一般不需要修改配置；

rdb保存的文件是dump.rdb；生产环境会备份dump.rdb文件；



**AOF（Append Only  File）**

将所有命令都记录下来，恢复的时候把这个文件全部执行一遍；

以日志的形式来记录每一个写操作，将Redis执行的所有执行记录下来（读操作不记录），只许追加文件但不可以改写文件，Redis启动之初会读取该文件重新构建数据，换言之，Redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作；

AOF保存的是appendonly.aof文件；

默认是不开启的，需要手动进行配置；appendonly     yes

- RDB持久化方式能够在指定的时间间隔内对数据进行快照存储；

- AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以Redis协议追加保存每次写的操作到文件末尾，Redis还能对AOF进行后台重写，使得AOF文件的体积不至于过大；

- 只做缓存，如果数据在服务器运行的时候存在，可以不使用任何持久化；

- 同时开启两种持久化方式

  在这种情况下，当Redis重启的时候会优先载入AOF文件来恢复原始数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集完整；

  RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件；不建议只使用AOF，因为RDB更适合于备份数据库，快速重启，而且不会有AOF可能存在的bug。

- 性能建议

### Redis缓存穿透和雪崩(面试高频)

读的请求先从Redis缓存中差，若Redis缓存中没有，到数据库中查；

**缓存穿透(数据库查不到)**

> 概念

缓存穿透的概念：用户想要查询一个数据，发现Redis内存数据库中没有，也就是缓存没有命中，于是向持久层数据库(mysql)查询。发现也没有，于是本次查询失败，当用户很多的时候，缓存都没有命中，都去请求持久层数据库，这样会给持久层数据库造成很大的压力，出现缓存穿透。

> 解决方案

**布隆过滤器**

布隆过滤器是一种数据结构，对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合规则则丢弃，从而避免了对底层存储系统的查询压力。

![布隆过滤器](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20201121130022958.png)

**缓存空对象**

当存储层不命中后，即使返回空对象也将其缓存起来，同时会设置一个过期时间，之后再访问这个数据会从缓存中获取，保护了后端数据源。

![缓存空对象](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20201121130225514.png)

缓存空对象会存在两个问题：

- 空值能够被存储起来，意味着缓存需要更多的空间存储更多的键，可能会存在很多的空值的键；
- 即使对控制设置了过期时间，还是会在缓存层和存储层的数据有一段时间窗口的不一致，这对于需要保持一致性的业务会有影响。



**缓存击穿(查询量大，缓存过期)(1个key)**

> 概述

缓存穿透和缓存击穿的区别：缓存击穿是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库。

当某个key在过期的瞬间，有大量的请求并发访问，这类数据一般是热点数据，由于缓存过期，会同时访问数据库来查询最新数据，并且写会缓存，会导致数据库瞬间压力过大。

> 解决方案

- 加互斥锁：使用分布式锁，保证对于每个key只有一个线程去查询后端服务，其他线程没有获得分布式锁的权限，因此只需要等待即可。这种方式将高并发的压力转移到了分布式锁，因此对分布式锁的考验很大。
- 设置热点数据永不过期：从缓存层面看，没有设置过期时间，不会出现热点key过期后产生的问题。



### 12.3 缓存雪崩(数据大批量消失)

> 概念

缓存雪崩，是指在某一个时间段，缓存集中过期失效，Redis宕机。

![缓存雪崩](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20201121131327148.png)

比较致命的缓存雪崩，是缓存服务器某个节点宕机或断网；

缓存服务结点的宕机，对数据库服务器造成的压力是不可预知的，有可能瞬间把数据库压垮。

双十一：停掉一些服务；

> 解决方案

- Redis高可用：搭建集群，异地多活
- 限流降级：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如某个key只允许一个线程查询和写缓存，其他线程等待。
- 数据预热：数据加热的含义就是在正式部署前，把可能的数据先访问一遍，这样部分可能大量访问的数据就会加载到缓存中，在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间尽量均匀。





## Part4：Redis设计与实现











## MongoDB

MongoDB 是一个基于文档(Document)的存储型的数据库，使用面向对象的思想，每条数据记录都是文档的对象。



















